{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jyjvG5wzv0t"
   },
   "source": [
    "# Scene Classifier\n",
    "\n",
    "This is my attempt to create a scene classifier in TensorFlow using Convolutional Neural Networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5btc6piDzuo8"
   },
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TQxZc8YpelIP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GBSmQVfTxnPC"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_dataset():\n",
    "    train_path = \"Dataset/seg_train\"\n",
    "    cv_path = \"Dataset/seg_test\"\n",
    "    pred_path = \"Dataset/seg_pred\"\n",
    "\n",
    "    classes = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "\n",
    "    train_paths = []\n",
    "    train_labels = []\n",
    "    for i in range(len(classes)):\n",
    "        fname = train_path + \"/\" + classes[i] #Dataset/seg_train/class[i]\n",
    "        for x in glob.iglob(fname + \"/*.jpg\"):\n",
    "            train_paths.append(x)\n",
    "            train_labels.append(i)\n",
    "  \n",
    "    cv_paths = []\n",
    "    cv_labels = []\n",
    "    for i in range(len(classes)):\n",
    "        fname = cv_path + \"/\" + classes[i] \n",
    "        for x in glob.iglob(fname + \"/*.jpg\"):\n",
    "            cv_paths.append(x)\n",
    "            cv_labels.append(i)\n",
    "\n",
    "    pred_paths = []\n",
    "    for x in glob.iglob(pred_path + \"/*.jpg\"):\n",
    "        pred_paths.append(x)\n",
    "\n",
    "    df_train = pd.DataFrame(list(zip(train_paths, train_labels)), columns=['X', 'Y']).sample(frac=1).reset_index(drop=True)\n",
    "    df_cv = pd.DataFrame(list(zip(cv_paths, cv_labels)), columns=['X', 'Y']).sample(frac=1).reset_index(drop=True)\n",
    "    df_pred = pd.DataFrame(pred_paths).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return (df_train, df_cv, df_pred)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "VP1vbypF1l_o",
    "outputId": "449111fe-8481-4ff1-8b7a-ed58208d281b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/seg_train/mountain/14437.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/seg_train/forest/6578.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/seg_train/buildings/19969.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/seg_train/forest/11072.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/seg_train/forest/8236.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14029</th>\n",
       "      <td>Dataset/seg_train/glacier/3003.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030</th>\n",
       "      <td>Dataset/seg_train/buildings/1630.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>Dataset/seg_train/sea/1394.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>Dataset/seg_train/glacier/12358.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>Dataset/seg_train/street/7601.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14034 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           X  Y\n",
       "0       Dataset/seg_train/mountain/14437.jpg  3\n",
       "1          Dataset/seg_train/forest/6578.jpg  1\n",
       "2      Dataset/seg_train/buildings/19969.jpg  0\n",
       "3         Dataset/seg_train/forest/11072.jpg  1\n",
       "4          Dataset/seg_train/forest/8236.jpg  1\n",
       "...                                      ... ..\n",
       "14029     Dataset/seg_train/glacier/3003.jpg  2\n",
       "14030   Dataset/seg_train/buildings/1630.jpg  0\n",
       "14031         Dataset/seg_train/sea/1394.jpg  4\n",
       "14032    Dataset/seg_train/glacier/12358.jpg  2\n",
       "14033      Dataset/seg_train/street/7601.jpg  5\n",
       "\n",
       "[14034 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_cv, df_test = load_dataset()\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U7DBPSqMeiJ5"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def data_generator(dataframe, batch_size=16):\n",
    "    m = dataframe.shape[0]\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i == m:\n",
    "            i = 0\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        for j in range(batch_size):\n",
    "            fname = dataframe.iloc[i, 0]\n",
    "            label = dataframe.iloc[i, 1]\n",
    "            y = np.zeros(6)\n",
    "            y[label] = 1\n",
    "            x = Image.open(fname)\n",
    "            x = x.resize((128, 128))\n",
    "            x = np.array(x)\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "            i += 1\n",
    "            if i == m:\n",
    "                i = 0\n",
    "\n",
    "        X_batch_np = np.array(X_batch)\n",
    "        Y_batch_np = np.array(Y_batch)\n",
    "        yield (X_batch_np, Y_batch_np)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbIGjDh-mRQ1"
   },
   "source": [
    "## Building Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HZMx2n9l21Z",
    "outputId": "3cdbcc8a-6168-4848-a3cd-8907260300f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-30 13:37:33.315756: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-30 13:37:33.775515: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-30 13:37:33.794333: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2021-06-30 13:37:33.794349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-server\n",
      "2021-06-30 13:37:33.794352: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-server\n",
      "2021-06-30 13:37:33.794388: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.31.0\n",
      "2021-06-30 13:37:33.794399: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.42.1\n",
      "2021-06-30 13:37:33.794402: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.42.1 does not match DSO version 465.31.0 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uazmVOIXnGwD"
   },
   "outputs": [],
   "source": [
    "def inception(x, filters_1x1, filters_3x3, filters_5x5, reg):\n",
    "    x1 = Conv2D(filters=filters_1x1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(reg))(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation(\"relu\")(x1)\n",
    "    \n",
    "    x3 = Conv2D(filters=filters_3x3, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(reg))(x)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation(\"relu\")(x3)\n",
    "    \n",
    "    x5 = Conv2D(filters=filters_5x5, kernel_size=(5, 5), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(reg))(x)\n",
    "    x5 = BatchNormalization()(x5)\n",
    "    x5 = Activation(\"relu\")(x5)\n",
    "    \n",
    "    output = Concatenate(axis=3)([x1, x3, x5])\n",
    "    return output\n",
    "\n",
    "def scene_classifier(width, height, depth, batch_size, reg=1e-8, drop=0.5):\n",
    "    input = Input(shape=(width, height, depth))\n",
    "    x = inception(input, filters_1x1=64, filters_3x3=64, filters_5x5=64, reg=reg)\n",
    "    x = inception(x, filters_1x1=64, filters_3x3=64, filters_5x5=64, reg=reg)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = inception(x, filters_1x1=128, filters_3x3=128, filters_5x5=128, reg=reg)\n",
    "    x = inception(x, filters_1x1=128, filters_3x3=128, filters_5x5=128, reg=reg)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = inception(x, filters_1x1=256, filters_3x3=256, filters_5x5=256, reg=reg)\n",
    "    x = inception(x, filters_1x1=256, filters_3x3=256, filters_5x5=256, reg=reg)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = inception(x, filters_1x1=512, filters_3x3=512, filters_5x5=512, reg=reg)\n",
    "    x = inception(x, filters_1x1=512, filters_3x3=512, filters_5x5=512, reg=reg)\n",
    "    x = inception(x, filters_1x1=512, filters_3x3=512, filters_5x5=512, reg=reg)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, kernel_regularizer=l2(reg), kernel_initializer=\"he_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    \n",
    "    x = Dense(2048, kernel_regularizer=l2(reg), kernel_initializer=\"he_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = Dense(2048, kernel_regularizer=l2(reg), kernel_initializer=\"he_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(drop)(x)\n",
    "\n",
    "    x = Dense(6, kernel_regularizer=l2(reg), kernel_initializer=\"glorot_uniform\")(x)\n",
    "    output = Activation(\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCfEaGfPuDQA",
    "outputId": "dca3e18a-cacd-4214-c0c3-41ce62cfd65d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-30 13:36:29.042175: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-06-30 13:36:29.042194: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-06-30 13:36:29.042913: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-06-30 13:36:29.043421: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-30 13:36:29.796256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-30 13:36:29.813022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3693130000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2#20\n",
    "LEARNING_RATE = 10**np.random.uniform(-8, 0, 1)\n",
    "REG = 10**np.random.uniform(-8, 0, 1)\n",
    "DROP = 10**np.random.uniform(0, 1, 1)\n",
    "\n",
    "\n",
    "tsteps = 10#int(df_train.shape[0]/BATCH_SIZE)\n",
    "cvsteps = 10#int(df_cv.shape[0]/BATCH_SIZE)\n",
    "\n",
    "t_gen = data_generator(df_train, batch_size=BATCH_SIZE)\n",
    "cv_gen = data_generator(df_cv, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "hparams = pd.DataFrame()\n",
    "\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    for lr in LEARNING_RATE:\n",
    "        for reg in REG:\n",
    "            for dp in DROP:\n",
    "                \n",
    "\n",
    "                opt = Adam(learning_rate=8e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, amsgrad=False)\n",
    "                model = scene_classifier(128, 128, 3, BATCH_SIZE, reg=0, drop=0)\n",
    "                model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "                training_hist = model.fit(x=t_gen, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    steps_per_epoch=tsteps,  \n",
    "                    validation_data=cv_gen,\n",
    "                    validation_steps=cvsteps,\n",
    "                    validation_batch_size=BATCH_SIZE, \n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard_callback])\n",
    "    \n",
    "                row = pd.Series(data=[training_hist.history['val_accuracy'][-1], training_hist.history['val_loss'][-1], lr, reg, dp], \n",
    "                               index=[\"val_acc\", \"val_loss\", \"learning rate\", \"L2\", \"dropout\"])\n",
    "                hparams.append(row, ignore_index=True)\n",
    "                \n",
    "                del model\n",
    "                del opt\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9fuIiK9xGBD"
   },
   "outputs": [],
   "source": [
    "hparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA9xyfyDLydv"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Scene-Classifier-TF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
